{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "924507dc",
   "metadata": {},
   "source": [
    "## 1.Preknowledge：[SAVE AND LOAD THE MODE](https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html)\n",
    "In this section we will look at how to persist model state with saving, loading and running model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df114aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01a4638",
   "metadata": {},
   "source": [
    "### Saving and Loading Model Weights\n",
    "PyTorch models store the learned parameters in an internal state dictionary, called **state_dict**. These can be persisted via the **torch.save** method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397c7234",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16(pretrained=True)\n",
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8121926",
   "metadata": {},
   "source": [
    "To load model weights, you need to create an instance of the same model first, and then load the parameters using **load_state_dict()** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd384c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16() # we do not specify pretrained=True, i.e. do not load default weights\n",
    "model.load_state_dict(torch.load('model_weights.pth'))\n",
    "model.eval() # 模型进入评估模式，尤其对dropout和BN有用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ec31dd",
   "metadata": {},
   "source": [
    "- note：Be sure to call **model.eval()** method before inferencing to set the dropout and batch normalization layers to evaluation mode. Failing to do this will yield inconsistent inference results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121d3dba",
   "metadata": {},
   "source": [
    "### Saving and Loading Models with Shapes\n",
    "When loading model weights, we needed to instantiate the model class first, because the class defines the structure of a network. We might want to save the structure of this class together with the model, in which case we can pass **model** (and not **model.state_dict()**) to the saving function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6213cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce38c930",
   "metadata": {},
   "source": [
    "We can then load the model like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df85c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47238a28",
   "metadata": {},
   "source": [
    "- note: This approach uses Python [pickle](https://docs.python.org/3/library/pickle.html) module when serializing the model, thus it relies on the actual class definition to be available when loading the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee00575",
   "metadata": {},
   "source": [
    "### [Saving and Loading a General Checkpoint](https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d99300",
   "metadata": {},
   "source": [
    "#### Save the general checkpoint\n",
    "Collect all relevant information and build your dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9886cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional information\n",
    "EPOCH = 5\n",
    "PATH = \"model.pt\" # 也可用pth，pkl等后缀保存路径\n",
    "LOSS = 0.4\n",
    "\n",
    "torch.save({\n",
    "            'epoch': EPOCH,\n",
    "            'model_state_dict': net.state_dict(),   # net是之前定义网络类的实例化\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': LOSS,\n",
    "            }, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0981c36f",
   "metadata": {},
   "source": [
    "#### Load the general checkpoint\n",
    "Remember to first initialize the model and optimizer, then load the dictionary locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84b0eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "model.eval()\n",
    "# - or -\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b3601e",
   "metadata": {},
   "source": [
    "You must call **model.eval()** to set dropout and batch normalization layers to evaluation mode before running inference. Failing to do this will yield inconsistent inference results.\n",
    "\n",
    "If you wish to resuming training, call **model.train()** to ensure these layers are in training mode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a8b281",
   "metadata": {},
   "source": [
    "## 2.Introduce nn.Module source code(Part II)\n",
    "### Part of the class [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module) source code is cited below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4a07b7",
   "metadata": {},
   "source": [
    "#### to()函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca7662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def to(self, *args, **kwargs):\n",
    "        r\"\"\"Moves and/or casts the parameters and buffers.\n",
    "\n",
    "        This can be called as\n",
    "\n",
    "        .. function:: to(device=None, dtype=None, non_blocking=False)  # to()函数签名有多种\n",
    "           :noindex:\n",
    "\n",
    "        .. function:: to(dtype, non_blocking=False)\n",
    "           :noindex:\n",
    "\n",
    "        .. function:: to(tensor, non_blocking=False)\n",
    "           :noindex:\n",
    "\n",
    "        .. function:: to(memory_format=torch.channels_last)\n",
    "           :noindex:\n",
    "           \n",
    "        ...... # 后面内容省略   \n",
    "        \n",
    "        .. note::\n",
    "            This method modifies the module in-place.\n",
    "\n",
    "        Examples::  # 例子\n",
    "\n",
    "            >>> linear = nn.Linear(2, 2)\n",
    "            >>> linear.weight\n",
    "            Parameter containing:\n",
    "            tensor([[ 0.1913, -0.3420],\n",
    "                    [-0.5113, -0.2325]])\n",
    "            >>> linear.to(torch.double)\n",
    "            Linear(in_features=2, out_features=2, bias=True)\n",
    "            >>> linear.weight\n",
    "            Parameter containing:\n",
    "            tensor([[ 0.1913, -0.3420],\n",
    "                    [-0.5113, -0.2325]], dtype=torch.float64)\n",
    "            >>> gpu1 = torch.device(\"cuda:1\")\n",
    "            >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n",
    "            Linear(in_features=2, out_features=2, bias=True)\n",
    "            >>> linear.weight\n",
    "            Parameter containing:\n",
    "            tensor([[ 0.1914, -0.3420],\n",
    "                    [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n",
    "            >>> cpu = torch.device(\"cpu\")\n",
    "            >>> linear.to(cpu)\n",
    "            Linear(in_features=2, out_features=2, bias=True)\n",
    "            >>> linear.weight\n",
    "            Parameter containing:\n",
    "            tensor([[ 0.1914, -0.3420],\n",
    "                    [-0.5112, -0.2324]], dtype=torch.float16)\n",
    "\n",
    "            >>> linear = nn.Linear(2, 2, bias=None).to(torch.cdouble)\n",
    "            >>> linear.weight\n",
    "            Parameter containing:\n",
    "            tensor([[ 0.3741+0.j,  0.2382+0.j],\n",
    "                    [ 0.5593+0.j, -0.4443+0.j]], dtype=torch.complex128)\n",
    "            >>> linear(torch.ones(3, 2, dtype=torch.cdouble))\n",
    "            tensor([[0.6122+0.j, 0.1150+0.j],\n",
    "                    [0.6122+0.j, 0.1150+0.j],\n",
    "                    [0.6122+0.j, 0.1150+0.j]], dtype=torch.complex128)\n",
    "\n",
    "        \"\"\"\n",
    "        ...... # 后面内容省略"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1d9051",
   "metadata": {},
   "source": [
    "to()函数示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c28c6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test(torch.nn.Module): # 自定义一个module\n",
    "    def __init__(self):\n",
    "        super(Test, self).__init__() # 在子类的init函数定义时一般要调用父类的init函数\n",
    "        self.linear1 = torch.nn.Linear(2, 3)\n",
    "        self.linear2 = torch.nn.Linear(3, 4)\n",
    "        self.batch_norm = torch.nn.BatchNorm2d(4)\n",
    "\n",
    "test_module = Test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "430761cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear1', Linear(in_features=2, out_features=3, bias=True)),\n",
       "             ('linear2', Linear(in_features=3, out_features=4, bias=True)),\n",
       "             ('batch_norm',\n",
       "              BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_module._modules #_modules属性返回一个有序字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2a77c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2, out_features=3, bias=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_module._modules['linear1'] # 得到linear1的module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b249742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.4898,  0.2476],\n",
       "        [ 0.4431, -0.5865],\n",
       "        [ 0.4365,  0.5435]], requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_module._modules['linear1'].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69a31a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_module._modules['linear1'].weight.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcf2a84f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Test(\n",
       "  (linear1): Linear(in_features=2, out_features=3, bias=True)\n",
       "  (linear2): Linear(in_features=3, out_features=4, bias=True)\n",
       "  (batch_norm): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_module.to(torch.double)  # 将其中所有数据类型改为double（float64）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9754208f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_module._modules['linear1'].weight.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5766ff91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Test(\n",
       "  (linear1): Linear(in_features=2, out_features=3, bias=True)\n",
       "  (linear2): Linear(in_features=3, out_features=4, bias=True)\n",
       "  (batch_norm): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_module.to(torch.float32) # 改回默认数据类型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687f2ec6",
   "metadata": {},
   "source": [
    "#### \\_\\_getattr__()函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59828ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def __getattr__(self, name: str) -> Union[Tensor, 'Module']:  # python的魔法函数之一，当访问不存在的属性时会抛出异常\n",
    "        if '_parameters' in self.__dict__:  # 有以下3个属性\n",
    "            _parameters = self.__dict__['_parameters']  # self为当前module自身，其返回的是当前model内定义的parameters\n",
    "            if name in _parameters:                     # 而其子module中的parameters则无法返回\n",
    "                return _parameters[name]  \n",
    "        if '_buffers' in self.__dict__:\n",
    "            _buffers = self.__dict__['_buffers']\n",
    "            if name in _buffers:\n",
    "                return _buffers[name]\n",
    "        if '_modules' in self.__dict__:\n",
    "            modules = self.__dict__['_modules']\n",
    "            if name in modules:\n",
    "                return modules[name]\n",
    "        raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n",
    "            type(self).__name__, name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89d631ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear1', Linear(in_features=2, out_features=3, bias=True)),\n",
       "             ('linear2', Linear(in_features=3, out_features=4, bias=True)),\n",
       "             ('batch_norm',\n",
       "              BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 解释上面为什么test_module可以调用_modules（因为getattr函数有这样一个属性（nn.Module类也有这样一个成员变量））\n",
    "test_module._modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e2998a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_module._parameters  # 返回空字典？因为调用_parameters并没有对test_module的所有子模块（linear1，2）进行遍历\n",
    "                         # 其只对当前对象自身进行搜索，Test类中未定义任何nn.Parameter对象，但其子模块（linear层）中有定义\n",
    "                         # 虽然输出空字典，不能理解为没有参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bc706af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_module._buffers # 原因同上"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bef424",
   "metadata": {},
   "source": [
    "#### _save_to_state_dict()函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43144c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _save_to_state_dict(self, destination, prefix, keep_vars): # 当前module的parameters和buffers存放在一个destination字典中\n",
    "        r\"\"\"Saves module state to `destination` dictionary, containing a state\n",
    "        of the module, but not its descendants. This is called on every\n",
    "        submodule in :meth:`~torch.nn.Module.state_dict`.\n",
    "\n",
    "        In rare cases, subclasses can achieve class-specific behavior by\n",
    "        overriding this method with custom logic.\n",
    "\n",
    "        Args:\n",
    "            destination (dict): a dict where state will be stored\n",
    "            prefix (str): the prefix for parameters and buffers used in this\n",
    "                module\n",
    "        \"\"\"\n",
    "        for name, param in self._parameters.items(): # 对当前module(不包括其中子module)的parameters遍历\n",
    "            if param is not None:\n",
    "                destination[prefix + name] = param if keep_vars else param.detach() # 放到字典中\n",
    "        for name, buf in self._buffers.items():     # 对当前module(不包括其中子module)的buffers遍历\n",
    "            if buf is not None and name not in self._non_persistent_buffers_set:\n",
    "                destination[prefix + name] = buf if keep_vars else buf.detach()\n",
    "        extra_state_key = prefix + _EXTRA_STATE_KEY_SUFFIX\n",
    "        if getattr(self.__class__, \"get_extra_state\", Module.get_extra_state) is not Module.get_extra_state:\n",
    "            destination[extra_state_key] = self.get_extra_state()\n",
    "\n",
    "    # The user can pass an optional arbitrary mappable object to `state_dict`, in which case `state_dict` returns\n",
    "    # back that same object. But if they pass nothing, an `OrederedDict` is created and returned.\n",
    "    \n",
    "# 其在state_dict()中被调用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860f419d",
   "metadata": {},
   "source": [
    "#### state_dict()函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6705e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def state_dict(self, destination=None, prefix='', keep_vars=False):\n",
    "        r\"\"\"Returns a dictionary containing a whole state of the module.\n",
    "\n",
    "        Both parameters and persistent buffers (e.g. running averages) are\n",
    "        included. Keys are corresponding parameter and buffer names.\n",
    "        Parameters and buffers set to ``None`` are not included.\n",
    "\n",
    "        Returns:\n",
    "            dict:\n",
    "                a dictionary containing a whole state of the module\n",
    "\n",
    "        Example::\n",
    "\n",
    "            >>> module.state_dict().keys()\n",
    "            ['bias', 'weight']\n",
    "\n",
    "        \"\"\"\n",
    "        if destination is None:\n",
    "            destination = OrderedDict()\n",
    "            destination._metadata = OrderedDict()\n",
    "        destination._metadata[prefix[:-1]] = local_metadata = dict(version=self._version)\n",
    "        self._save_to_state_dict(destination, prefix, keep_vars) # 当前module的参数和buffer放入字典中\n",
    "        for name, module in self._modules.items(): # 对当前module的子module进行遍历\n",
    "            if module is not None: # 如果有子module\n",
    "                module.state_dict(destination, prefix + name + '.', keep_vars=keep_vars) # 子module调用state_dict,参数和buffer放入字典\n",
    "        for hook in self._state_dict_hooks.values():\n",
    "            hook_result = hook(self, destination, prefix, local_metadata)\n",
    "            if hook_result is not None:\n",
    "                destination = hook_result\n",
    "        return destination  # 返回destination字典\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ddb8d8",
   "metadata": {},
   "source": [
    "state_dict()函数示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbe58c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear1.weight',\n",
       "              tensor([[ 0.4898,  0.2476],\n",
       "                      [ 0.4431, -0.5865],\n",
       "                      [ 0.4365,  0.5435]])),\n",
       "             ('linear1.bias', tensor([ 0.0715, -0.1448, -0.1111])),\n",
       "             ('linear2.weight',\n",
       "              tensor([[-0.1690,  0.2995,  0.2924],\n",
       "                      [-0.2389,  0.4674, -0.3988],\n",
       "                      [-0.5677,  0.5025, -0.4594],\n",
       "                      [-0.1568, -0.1094, -0.3007]])),\n",
       "             ('linear2.bias', tensor([-0.2783, -0.2626,  0.3051, -0.0977])),\n",
       "             ('batch_norm.weight', tensor([1., 1., 1., 1.])),\n",
       "             ('batch_norm.bias', tensor([0., 0., 0., 0.])),\n",
       "             ('batch_norm.running_mean', tensor([0., 0., 0., 0.])),\n",
       "             ('batch_norm.running_var', tensor([1., 1., 1., 1.])),\n",
       "             ('batch_norm.num_batches_tracked', tensor(0))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_module.state_dict() # 输出的最后三项为buffers，其余为parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acc2e37f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4898,  0.2476],\n",
       "        [ 0.4431, -0.5865],\n",
       "        [ 0.4365,  0.5435]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_module.state_dict()['linear1.weight']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5af85d",
   "metadata": {},
   "source": [
    "#### _load_from_state_dict()函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc30c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _load_from_state_dict(self, state_dict, prefix, local_metadata, strict, # 从state_dict得到参数和buffer的值，\n",
    "                              missing_keys, unexpected_keys, error_msgs):       # 然后赋给当前module的变量\n",
    "        r\"\"\"Copies parameters and buffers from :attr:`state_dict` into only\n",
    "        this module, but not its descendants. This is called on every submodule\n",
    "        in :meth:`~torch.nn.Module.load_state_dict`. Metadata saved for this\n",
    "        module in input :attr:`state_dict` is provided as :attr:`local_metadata`.\n",
    "        For state dicts without metadata, :attr:`local_metadata` is empty.\n",
    "        Subclasses can achieve class-specific backward compatible loading using\n",
    "        the version number at `local_metadata.get(\"version\", None)`.\n",
    "\n",
    "        .. note::\n",
    "            :attr:`state_dict` is not the same object as the input\n",
    "            :attr:`state_dict` to :meth:`~torch.nn.Module.load_state_dict`. So\n",
    "            it can be modified.\n",
    "\n",
    "        Args:\n",
    "            state_dict (dict): a dict containing parameters and\n",
    "                persistent buffers.\n",
    "            prefix (str): the prefix for parameters and buffers used in this\n",
    "                module\n",
    "            local_metadata (dict): a dict containing the metadata for this module.\n",
    "                See\n",
    "            strict (bool): whether to strictly enforce that the keys in\n",
    "                :attr:`state_dict` with :attr:`prefix` match the names of\n",
    "                parameters and buffers in this module\n",
    "            missing_keys (list of str): if ``strict=True``, add missing keys to\n",
    "                this list\n",
    "            unexpected_keys (list of str): if ``strict=True``, add unexpected\n",
    "                keys to this list\n",
    "            error_msgs (list of str): error messages should be added to this\n",
    "                list, and will be reported together in\n",
    "                :meth:`~torch.nn.Module.load_state_dict`\n",
    "        \"\"\"\n",
    "        for hook in self._load_state_dict_pre_hooks.values():\n",
    "            hook(state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\n",
    "\n",
    "        persistent_buffers = {k: v for k, v in self._buffers.items() if k not in self._non_persistent_buffers_set}\n",
    "        local_name_params = itertools.chain(self._parameters.items(), persistent_buffers.items())\n",
    "        local_state = {k: v for k, v in local_name_params if v is not None} # 当前module中所有参数和buffer的键放入local_state中\n",
    "\n",
    "        for name, param in local_state.items(): # 对local_state遍历\n",
    "            key = prefix + name\n",
    "            if key in state_dict: # 如果local_state的键在state_dict中\n",
    "                input_param = state_dict[key] \n",
    "                if not torch.overrides.is_tensor_like(input_param):\n",
    "                    error_msgs.append('While copying the parameter named \"{}\", '\n",
    "                                      'expected torch.Tensor or Tensor-like object from checkpoint but '\n",
    "                                      'received {}'\n",
    "                                      .format(key, type(input_param)))\n",
    "                    continue\n",
    "\n",
    "                # This is used to avoid copying uninitialized parameters into\n",
    "                # non-lazy modules, since they dont have the hook to do the checks\n",
    "                # in such case, it will error when accessing the .shape attribute.\n",
    "                is_param_lazy = torch.nn.parameter.is_lazy(param)\n",
    "                # Backward compatibility: loading 1-dim tensor from 0.3.* to version 0.4+\n",
    "                if not is_param_lazy and len(param.shape) == 0 and len(input_param.shape) == 1:\n",
    "                    input_param = input_param[0]\n",
    "\n",
    "                if not is_param_lazy and input_param.shape != param.shape:\n",
    "                    # local shape should match the one in checkpoint\n",
    "                    error_msgs.append('size mismatch for {}: copying a param with shape {} from checkpoint, '\n",
    "                                      'the shape in current model is {}.'\n",
    "                                      .format(key, input_param.shape, param.shape))\n",
    "                    continue\n",
    "                try:\n",
    "                    with torch.no_grad():\n",
    "                        param.copy_(input_param)  # 赋值的操作，input_param是从state_dict获得的\n",
    "                except Exception as ex:\n",
    "                    error_msgs.append('While copying the parameter named \"{}\", '\n",
    "                                      'whose dimensions in the model are {} and '\n",
    "                                      'whose dimensions in the checkpoint are {}, '\n",
    "                                      'an exception occurred : {}.'\n",
    "                                      .format(key, param.size(), input_param.size(), ex.args))\n",
    "            elif strict:\n",
    "                missing_keys.append(key)\n",
    "\n",
    "        extra_state_key = prefix + _EXTRA_STATE_KEY_SUFFIX\n",
    "        if getattr(self.__class__, \"set_extra_state\", Module.set_extra_state) is not Module.set_extra_state:\n",
    "            if extra_state_key in state_dict:\n",
    "                self.set_extra_state(state_dict[extra_state_key])\n",
    "            elif strict:\n",
    "                missing_keys.append(extra_state_key)\n",
    "        elif strict and (extra_state_key in state_dict):\n",
    "            unexpected_keys.append(extra_state_key)\n",
    "\n",
    "        if strict:\n",
    "            for key in state_dict.keys():\n",
    "                if key.startswith(prefix) and key != extra_state_key:\n",
    "                    input_name = key[len(prefix):]\n",
    "                    input_name = input_name.split('.', 1)[0]  # get the name of param/buffer/child\n",
    "                    if input_name not in self._modules and input_name not in local_state:\n",
    "                        unexpected_keys.append(key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6097540e",
   "metadata": {},
   "source": [
    "#### load_state_dict()函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9654e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def load_state_dict(self, state_dict: 'OrderedDict[str, Tensor]',    \n",
    "                        strict: bool = True):\n",
    "        r\"\"\"Copies parameters and buffers from :attr:`state_dict` into\n",
    "        this module and its descendants. If :attr:`strict` is ``True``, then\n",
    "        the keys of :attr:`state_dict` must exactly match the keys returned\n",
    "        by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
    "\n",
    "        Args:\n",
    "            state_dict (dict): a dict containing parameters and\n",
    "                persistent buffers.\n",
    "            strict (bool, optional): whether to strictly enforce that the keys\n",
    "                in :attr:`state_dict` match the keys returned by this module's\n",
    "                :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
    "\n",
    "        Returns:\n",
    "            ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n",
    "                * **missing_keys** is a list of str containing the missing keys\n",
    "                * **unexpected_keys** is a list of str containing the unexpected keys\n",
    "\n",
    "        Note:\n",
    "            If a parameter or buffer is registered as ``None`` and its corresponding key\n",
    "            exists in :attr:`state_dict`, :meth:`load_state_dict` will raise a\n",
    "            ``RuntimeError``.\n",
    "        \"\"\"\n",
    "        missing_keys: List[str] = []\n",
    "        unexpected_keys: List[str] = []\n",
    "        error_msgs: List[str] = []\n",
    "\n",
    "        # copy state_dict so _load_from_state_dict can modify it\n",
    "        metadata = getattr(state_dict, '_metadata', None)\n",
    "        state_dict = state_dict.copy()\n",
    "        if metadata is not None:\n",
    "            # mypy isn't aware that \"_metadata\" exists in state_dict\n",
    "            state_dict._metadata = metadata  # type: ignore[attr-defined]\n",
    "\n",
    "        def load(module, prefix=''):   # 调用了load()函数，函数中调用了_load_from_state_dict()函数\n",
    "            local_metadata = {} if metadata is None else metadata.get(prefix[:-1], {})\n",
    "            module._load_from_state_dict(\n",
    "                state_dict, prefix, local_metadata, True, missing_keys, unexpected_keys, error_msgs)\n",
    "            for name, child in module._modules.items():\n",
    "                if child is not None:\n",
    "                    load(child, prefix + name + '.')\n",
    "\n",
    "        load(self)\n",
    "        del load\n",
    "\n",
    "        if strict:\n",
    "            if len(unexpected_keys) > 0:\n",
    "                error_msgs.insert(\n",
    "                    0, 'Unexpected key(s) in state_dict: {}. '.format(\n",
    "                        ', '.join('\"{}\"'.format(k) for k in unexpected_keys)))\n",
    "            if len(missing_keys) > 0:\n",
    "                error_msgs.insert(\n",
    "                    0, 'Missing key(s) in state_dict: {}. '.format(\n",
    "                        ', '.join('\"{}\"'.format(k) for k in missing_keys)))\n",
    "\n",
    "        if len(error_msgs) > 0:\n",
    "            raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n",
    "                               self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
    "        return _IncompatibleKeys(missing_keys, unexpected_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ad9860",
   "metadata": {},
   "source": [
    "#### parameters()函数（ buffers()函数与之相似，仅以parameters()函数为例 ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d976c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def parameters(self, recurse: bool = True) -> Iterator[Parameter]:\n",
    "        r\"\"\"Returns an iterator over module parameters.\n",
    "\n",
    "        This is typically passed to an optimizer.\n",
    "\n",
    "        Args:\n",
    "            recurse (bool): if True, then yields parameters of this module\n",
    "                and all submodules. Otherwise, yields only parameters that\n",
    "                are direct members of this module.\n",
    "\n",
    "        Yields:\n",
    "            Parameter: module parameter\n",
    "\n",
    "        Example::\n",
    "\n",
    "            >>> for param in model.parameters():\n",
    "            >>>     print(type(param), param.size())\n",
    "            <class 'torch.Tensor'> (20L,)\n",
    "            <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
    "\n",
    "        \"\"\"\n",
    "        for name, param in self.named_parameters(recurse=recurse): # 调用named_parameters()函数对参数遍历\n",
    "            yield param    # 返回迭代器\n",
    "            \n",
    "# 要和_parameters区分开，_parameters为一个attribute(属性)，也可理解为一个成员变量；而parameters()为一函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc13cca",
   "metadata": {},
   "source": [
    "parameters()函数示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4b4a512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.4898,  0.2476],\n",
      "        [ 0.4431, -0.5865],\n",
      "        [ 0.4365,  0.5435]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0715, -0.1448, -0.1111], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1690,  0.2995,  0.2924],\n",
      "        [-0.2389,  0.4674, -0.3988],\n",
      "        [-0.5677,  0.5025, -0.4594],\n",
      "        [-0.1568, -0.1094, -0.3007]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2783, -0.2626,  0.3051, -0.0977], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in test_module.parameters():  # 因为其返回迭代器，我们对它进行遍历\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028c9c5e",
   "metadata": {},
   "source": [
    "#### named_parameters()函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01c4dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 在parameters()函数中被调用，用于对module和子module中的parameters进行遍历\n",
    "    def named_parameters(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, Parameter]]:\n",
    "        r\"\"\"Returns an iterator over module parameters, yielding both the\n",
    "        name of the parameter as well as the parameter itself.\n",
    "\n",
    "        Args:\n",
    "            prefix (str): prefix to prepend to all parameter names.\n",
    "            recurse (bool): if True, then yields parameters of this module\n",
    "                and all submodules. Otherwise, yields only parameters that\n",
    "                are direct members of this module.\n",
    "\n",
    "        Yields:\n",
    "            (string, Parameter): Tuple containing the name and parameter\n",
    "\n",
    "        Example::\n",
    "\n",
    "            >>> for name, param in self.named_parameters():\n",
    "            >>>    if name in ['bias']:\n",
    "            >>>        print(param.size())\n",
    "\n",
    "        \"\"\"\n",
    "        gen = self._named_members(      # 调用了_name_members()函数\n",
    "            lambda module: module._parameters.items(), # lambda函数返回传入的module自身的参数（包含名称和参数值信息）\n",
    "            prefix=prefix, recurse=recurse)\n",
    "        for elem in gen:\n",
    "            yield elem     # 返回迭代器（名称和参数值）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23209d4a",
   "metadata": {},
   "source": [
    "#### _named_members()函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35109de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _named_members(self, get_members_fn, prefix='', recurse=True): # 在被上面的函数调用时传入的get_members_fn就是lambda函数\n",
    "        r\"\"\"Helper method for yielding various names + members of modules.\"\"\"\n",
    "        memo = set()\n",
    "        modules = self.named_modules(prefix=prefix) if recurse else [(prefix, self)] # 对named_modules调用，返回所有子module\n",
    "        for module_prefix, module in modules:\n",
    "            members = get_members_fn(module)\n",
    "            for k, v in members:\n",
    "                if v is None or v in memo:\n",
    "                    continue\n",
    "                memo.add(v)\n",
    "                name = module_prefix + ('.' if module_prefix else '') + k\n",
    "                yield name, v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c121f865",
   "metadata": {},
   "source": [
    "named_parameters()函数示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b5c6f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('linear1.weight', Parameter containing:\n",
      "tensor([[ 0.4898,  0.2476],\n",
      "        [ 0.4431, -0.5865],\n",
      "        [ 0.4365,  0.5435]], requires_grad=True))\n",
      "('linear1.bias', Parameter containing:\n",
      "tensor([ 0.0715, -0.1448, -0.1111], requires_grad=True))\n",
      "('linear2.weight', Parameter containing:\n",
      "tensor([[-0.1690,  0.2995,  0.2924],\n",
      "        [-0.2389,  0.4674, -0.3988],\n",
      "        [-0.5677,  0.5025, -0.4594],\n",
      "        [-0.1568, -0.1094, -0.3007]], requires_grad=True))\n",
      "('linear2.bias', Parameter containing:\n",
      "tensor([-0.2783, -0.2626,  0.3051, -0.0977], requires_grad=True))\n",
      "('batch_norm.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1.], requires_grad=True))\n",
      "('batch_norm.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0.], requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "for p in test_module.named_parameters():\n",
    "    print(p) # 返回参数键和值组成的元组"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bc3533",
   "metadata": {},
   "source": [
    "#### children()函数 和 named_children()函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ac4abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def children(self) -> Iterator['Module']:\n",
    "        r\"\"\"Returns an iterator over immediate children modules.\n",
    "\n",
    "        Yields:\n",
    "            Module: a child module\n",
    "        \"\"\"\n",
    "        for name, module in self.named_children(): # 调用named_children\n",
    "            yield module # 仅返回子module本身的迭代器\n",
    "\n",
    "    def named_children(self) -> Iterator[Tuple[str, 'Module']]: # 返回迭代器\n",
    "        r\"\"\"Returns an iterator over immediate children modules, yielding both\n",
    "        the name of the module as well as the module itself.\n",
    "\n",
    "        Yields:\n",
    "            (string, Module): Tuple containing a name and child module\n",
    "\n",
    "        Example::\n",
    "\n",
    "            >>> for name, module in model.named_children():\n",
    "            >>>     if name in ['conv4', 'conv5']:\n",
    "            >>>         print(module)\n",
    "\n",
    "        \"\"\"\n",
    "        memo = set() # 创建备忘录\n",
    "        for name, module in self._modules.items(): # 遍历所有子module\n",
    "            if module is not None and module not in memo: # 如果有子module且子module不在备忘录中\n",
    "                memo.add(module) # 将子module加入备忘录\n",
    "                yield name, module # 名字和子module的迭代器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea666940",
   "metadata": {},
   "source": [
    "children()函数 和 named_children()函数示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b32c498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('linear1', Linear(in_features=2, out_features=3, bias=True))\n",
      "('linear2', Linear(in_features=3, out_features=4, bias=True))\n",
      "('batch_norm', BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n"
     ]
    }
   ],
   "source": [
    "for p in test_module.named_children():\n",
    "    print(p) # 返回子module键和值组成的元组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ddbc59c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear1', Linear(in_features=2, out_features=3, bias=True)),\n",
       "             ('linear2', Linear(in_features=3, out_features=4, bias=True)),\n",
       "             ('batch_norm',\n",
       "              BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_module._modules # 调用_modules的attribute返回的是一个有序字典，而.named_children()函数返回的是元组的迭代器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c79aec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=2, out_features=3, bias=True)\n",
      "Linear(in_features=3, out_features=4, bias=True)\n",
      "BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"
     ]
    }
   ],
   "source": [
    "for p in test_module.children():\n",
    "    print(p) # 返回子module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122c80e7",
   "metadata": {},
   "source": [
    "#### modules()函数 和 named_modules()函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883edf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def modules(self) -> Iterator['Module']:\n",
    "        r\"\"\"Returns an iterator over all modules in the network.\n",
    "\n",
    "        Yields:\n",
    "            Module: a module in the network\n",
    "\n",
    "        Note:\n",
    "            Duplicate modules are returned only once. In the following\n",
    "            example, ``l`` will be returned only once.\n",
    "\n",
    "        Example::\n",
    "\n",
    "            >>> l = nn.Linear(2, 2)\n",
    "            >>> net = nn.Sequential(l, l)\n",
    "            >>> for idx, m in enumerate(net.modules()):\n",
    "                    print(idx, '->', m)\n",
    "\n",
    "            0 -> Sequential(\n",
    "              (0): Linear(in_features=2, out_features=2, bias=True)\n",
    "              (1): Linear(in_features=2, out_features=2, bias=True)\n",
    "            )\n",
    "            1 -> Linear(in_features=2, out_features=2, bias=True)\n",
    "\n",
    "        \"\"\"\n",
    "        for _, module in self.named_modules(): # 调用named_modules()函数\n",
    "            yield module  # 仅返回module的迭代器 \n",
    "\n",
    "    def named_modules(self, memo: Optional[Set['Module']] = None, prefix: str = '', remove_duplicate: bool = True):\n",
    "        r\"\"\"Returns an iterator over all modules in the network, yielding\n",
    "        both the name of the module as well as the module itself.\n",
    "\n",
    "        Args:\n",
    "            memo: a memo to store the set of modules already added to the result\n",
    "            prefix: a prefix that will be added to the name of the module\n",
    "            remove_duplicate: whether to remove the duplicated module instances in the result\n",
    "                or not\n",
    "\n",
    "        Yields:\n",
    "            (string, Module): Tuple of name and module\n",
    "\n",
    "        Note:\n",
    "            Duplicate modules are returned only once. In the following\n",
    "            example, ``l`` will be returned only once.\n",
    "\n",
    "        Example::\n",
    "\n",
    "            >>> l = nn.Linear(2, 2)\n",
    "            >>> net = nn.Sequential(l, l)\n",
    "            >>> for idx, m in enumerate(net.named_modules()):\n",
    "                    print(idx, '->', m)\n",
    "\n",
    "            0 -> ('', Sequential(\n",
    "              (0): Linear(in_features=2, out_features=2, bias=True)\n",
    "              (1): Linear(in_features=2, out_features=2, bias=True)\n",
    "            ))\n",
    "            1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if memo is None:\n",
    "            memo = set() # 创建备忘录 \n",
    "        if self not in memo: # 自身不在备忘录中\n",
    "            if remove_duplicate:\n",
    "                memo.add(self)\n",
    "            yield prefix, self # 返回perfix和自身module的迭代器\n",
    "            for name, module in self._modules.items(): # 返回自身module后再对子module遍历\n",
    "                if module is None:\n",
    "                    continue\n",
    "                submodule_prefix = prefix + ('.' if prefix else '') + name\n",
    "                for m in module.named_modules(memo, submodule_prefix, remove_duplicate):\n",
    "                    yield m # 返回子module的迭代器（名称和子module的tuple）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696a85a2",
   "metadata": {},
   "source": [
    "modules()函数 和 named_modules()函数示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6b00cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('', Test(\n",
      "  (linear1): Linear(in_features=2, out_features=3, bias=True)\n",
      "  (linear2): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (batch_norm): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "))\n",
      "('linear1', Linear(in_features=2, out_features=3, bias=True))\n",
      "('linear2', Linear(in_features=3, out_features=4, bias=True))\n",
      "('batch_norm', BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n"
     ]
    }
   ],
   "source": [
    "for p in test_module.named_modules():\n",
    "    print(p) # 返回4个module，自身和其余3个子module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23c9be91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear1', Linear(in_features=2, out_features=3, bias=True)),\n",
       "             ('linear2', Linear(in_features=3, out_features=4, bias=True)),\n",
       "             ('batch_norm',\n",
       "              BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_module._modules # _modules的attribute只返回子module组成的有序字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dfe9878e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test(\n",
      "  (linear1): Linear(in_features=2, out_features=3, bias=True)\n",
      "  (linear2): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (batch_norm): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "\n",
      "\n",
      "Linear(in_features=2, out_features=3, bias=True)\n",
      "\n",
      "\n",
      "Linear(in_features=3, out_features=4, bias=True)\n",
      "\n",
      "\n",
      "BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for p in test_module.modules():\n",
    "    print(p) # 返回4个module，自身和其余3个子module, 但不返回自身module的prefix和子module的名称\n",
    "    print('\\n') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
